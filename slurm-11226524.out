| distributed init (rank 2): env://
| distributed init (rank 3): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(aa='rand-m9-mstd0.5-inc1', batch_size=16, clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='./data', data_set='CIFAR10', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, drop=0.0, drop_block=None, drop_path=0.1, embed_dim=48, epochs=100, eval=False, gpu=0, inat_category='name', input_size=224, local_up_to_layer=10, locality_strength=1.0, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model='convit_tiny', model_ema=False, model_ema_decay=0.99996, model_ema_force_cpu=False, momentum=0.9, nb_classes=None, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='exp/cvt-tiny/c10', patience_epochs=10, pin_mem=True, pretrained=False, rank=0, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='', sampling_ratio=1.0, save_every=None, sched='cosine', seed=0, smoothing=0.1, start_epoch=0, train_interpolation='bicubic', warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.05, world_size=4)
Files already downloaded and verified
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
Files already downloaded and verified
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
Creating model: convit_tiny
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  cpuset_checked))
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (2): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (3): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (4): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (5): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (6): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (7): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (8): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (9): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): GPSA(
        (qk): Linear(in_features=192, out_features=384, bias=False)
        (v): Linear(in_features=192, out_features=192, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pos_proj): Linear(in_features=3, out_features=4, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (10): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MHSA(
        (qkv): Linear(in_features=192, out_features=576, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (11): Block(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MHSA(
        (qkv): Linear(in_features=192, out_features=576, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (fc2): Linear(in_features=768, out_features=192, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=192, out_features=10, bias=True)
)
number of params: 5519442
Start training
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:365: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
Epoch: [0]  [  0/780]  eta: 4:54:30  lr: 0.000001  loss: 2.3531 (2.3531)  time: 22.6543  data: 21.2205  max mem: 908
Epoch: [0]  [ 10/780]  eta: 0:27:55  lr: 0.000001  loss: 2.3212 (2.3107)  time: 2.1756  data: 1.9292  max mem: 970
Epoch: [0]  [ 20/780]  eta: 0:15:09  lr: 0.000001  loss: 2.3212 (2.3176)  time: 0.1236  data: 0.0001  max mem: 970
Epoch: [0]  [ 30/780]  eta: 0:10:39  lr: 0.000001  loss: 2.3176 (2.3175)  time: 0.1258  data: 0.0006  max mem: 970
Epoch: [0]  [ 40/780]  eta: 0:08:19  lr: 0.000001  loss: 2.3154 (2.3268)  time: 0.1275  data: 0.0006  max mem: 970
Epoch: [0]  [ 50/780]  eta: 0:06:54  lr: 0.000001  loss: 2.3072 (2.3214)  time: 0.1255  data: 0.0031  max mem: 970
Epoch: [0]  [ 60/780]  eta: 0:05:56  lr: 0.000001  loss: 2.2919 (2.3160)  time: 0.1265  data: 0.0031  max mem: 970
Epoch: [0]  [ 70/780]  eta: 0:05:14  lr: 0.000001  loss: 2.2920 (2.3150)  time: 0.1242  data: 0.0002  max mem: 970
Epoch: [0]  [ 80/780]  eta: 0:04:42  lr: 0.000001  loss: 2.3028 (2.3128)  time: 0.1263  data: 0.0002  max mem: 970
Epoch: [0]  [ 90/780]  eta: 0:04:17  lr: 0.000001  loss: 2.3116 (2.3136)  time: 0.1245  data: 0.0001  max mem: 970
Epoch: [0]  [100/780]  eta: 0:03:56  lr: 0.000001  loss: 2.2979 (2.3089)  time: 0.1234  data: 0.0001  max mem: 970
Epoch: [0]  [110/780]  eta: 0:03:39  lr: 0.000001  loss: 2.2707 (2.3078)  time: 0.1248  data: 0.0007  max mem: 970
Epoch: [0]  [120/780]  eta: 0:03:25  lr: 0.000001  loss: 2.3129 (2.3088)  time: 0.1210  data: 0.0007  max mem: 970
Epoch: [0]  [130/780]  eta: 0:03:12  lr: 0.000001  loss: 2.2950 (2.3064)  time: 0.1221  data: 0.0022  max mem: 970
Epoch: [0]  [140/780]  eta: 0:03:01  lr: 0.000001  loss: 2.2774 (2.3051)  time: 0.1220  data: 0.0041  max mem: 970
Epoch: [0]  [150/780]  eta: 0:02:52  lr: 0.000001  loss: 2.3025 (2.3050)  time: 0.1181  data: 0.0021  max mem: 970
Epoch: [0]  [160/780]  eta: 0:02:43  lr: 0.000001  loss: 2.2854 (2.3027)  time: 0.1187  data: 0.0003  max mem: 970
Epoch: [0]  [170/780]  eta: 0:02:35  lr: 0.000001  loss: 2.2870 (2.3026)  time: 0.1223  data: 0.0016  max mem: 970
Epoch: [0]  [180/780]  eta: 0:02:28  lr: 0.000001  loss: 2.2995 (2.3022)  time: 0.1207  data: 0.0021  max mem: 970
Epoch: [0]  [190/780]  eta: 0:02:22  lr: 0.000001  loss: 2.2946 (2.3020)  time: 0.1190  data: 0.0006  max mem: 970
Epoch: [0]  [200/780]  eta: 0:02:16  lr: 0.000001  loss: 2.2811 (2.3007)  time: 0.1195  data: 0.0002  max mem: 970
Epoch: [0]  [210/780]  eta: 0:02:10  lr: 0.000001  loss: 2.2612 (2.2996)  time: 0.1190  data: 0.0006  max mem: 970
Epoch: [0]  [220/780]  eta: 0:02:05  lr: 0.000001  loss: 2.2754 (2.2992)  time: 0.1226  data: 0.0014  max mem: 970
Epoch: [0]  [230/780]  eta: 0:02:01  lr: 0.000001  loss: 2.2818 (2.2985)  time: 0.1229  data: 0.0015  max mem: 970
Epoch: [0]  [240/780]  eta: 0:01:56  lr: 0.000001  loss: 2.2823 (2.2986)  time: 0.1201  data: 0.0006  max mem: 970
Epoch: [0]  [250/780]  eta: 0:01:52  lr: 0.000001  loss: 2.2844 (2.2973)  time: 0.1184  data: 0.0005  max mem: 970
Epoch: [0]  [260/780]  eta: 0:01:48  lr: 0.000001  loss: 2.2766 (2.2963)  time: 0.1185  data: 0.0006  max mem: 970
Epoch: [0]  [270/780]  eta: 0:01:44  lr: 0.000001  loss: 2.2766 (2.2958)  time: 0.1221  data: 0.0002  max mem: 970
Epoch: [0]  [280/780]  eta: 0:01:41  lr: 0.000001  loss: 2.2991 (2.2958)  time: 0.1258  data: 0.0001  max mem: 970
Epoch: [0]  [290/780]  eta: 0:01:37  lr: 0.000001  loss: 2.2729 (2.2947)  time: 0.1233  data: 0.0006  max mem: 970
Epoch: [0]  [300/780]  eta: 0:01:34  lr: 0.000001  loss: 2.2753 (2.2951)  time: 0.1215  data: 0.0006  max mem: 970
Epoch: [0]  [310/780]  eta: 0:01:31  lr: 0.000001  loss: 2.3000 (2.2945)  time: 0.1250  data: 0.0003  max mem: 970
Epoch: [0]  [320/780]  eta: 0:01:28  lr: 0.000001  loss: 2.2746 (2.2949)  time: 0.1264  data: 0.0008  max mem: 970
Epoch: [0]  [330/780]  eta: 0:01:25  lr: 0.000001  loss: 2.2836 (2.2939)  time: 0.1238  data: 0.0008  max mem: 970
Epoch: [0]  [340/780]  eta: 0:01:23  lr: 0.000001  loss: 2.2578 (2.2926)  time: 0.1237  data: 0.0013  max mem: 970
Epoch: [0]  [350/780]  eta: 0:01:20  lr: 0.000001  loss: 2.2578 (2.2925)  time: 0.1229  data: 0.0012  max mem: 970
Epoch: [0]  [360/780]  eta: 0:01:17  lr: 0.000001  loss: 2.2591 (2.2917)  time: 0.1222  data: 0.0002  max mem: 970
Epoch: [0]  [370/780]  eta: 0:01:15  lr: 0.000001  loss: 2.2591 (2.2907)  time: 0.1218  data: 0.0010  max mem: 970
Epoch: [0]  [380/780]  eta: 0:01:12  lr: 0.000001  loss: 2.2953 (2.2912)  time: 0.1203  data: 0.0009  max mem: 970
Epoch: [0]  [390/780]  eta: 0:01:10  lr: 0.000001  loss: 2.3000 (2.2908)  time: 0.1220  data: 0.0001  max mem: 970
Epoch: [0]  [400/780]  eta: 0:01:07  lr: 0.000001  loss: 2.2777 (2.2909)  time: 0.1225  data: 0.0001  max mem: 970
Epoch: [0]  [410/780]  eta: 0:01:05  lr: 0.000001  loss: 2.2898 (2.2910)  time: 0.1254  data: 0.0008  max mem: 970
Epoch: [0]  [420/780]  eta: 0:01:03  lr: 0.000001  loss: 2.2805 (2.2902)  time: 0.1263  data: 0.0012  max mem: 970
Epoch: [0]  [430/780]  eta: 0:01:01  lr: 0.000001  loss: 2.2672 (2.2899)  time: 0.1215  data: 0.0005  max mem: 970
Epoch: [0]  [440/780]  eta: 0:00:59  lr: 0.000001  loss: 2.2590 (2.2890)  time: 0.1191  data: 0.0008  max mem: 970
Epoch: [0]  [450/780]  eta: 0:00:56  lr: 0.000001  loss: 2.2609 (2.2888)  time: 0.1207  data: 0.0007  max mem: 970
Epoch: [0]  [460/780]  eta: 0:00:54  lr: 0.000001  loss: 2.2636 (2.2882)  time: 0.1197  data: 0.0008  max mem: 970
Epoch: [0]  [470/780]  eta: 0:00:52  lr: 0.000001  loss: 2.2485 (2.2872)  time: 0.1193  data: 0.0026  max mem: 970
Epoch: [0]  [480/780]  eta: 0:00:50  lr: 0.000001  loss: 2.2485 (2.2873)  time: 0.1257  data: 0.0019  max mem: 970
Epoch: [0]  [490/780]  eta: 0:00:48  lr: 0.000001  loss: 2.2753 (2.2872)  time: 0.1260  data: 0.0001  max mem: 970
Epoch: [0]  [500/780]  eta: 0:00:46  lr: 0.000001  loss: 2.2633 (2.2871)  time: 0.1240  data: 0.0013  max mem: 970
Epoch: [0]  [510/780]  eta: 0:00:45  lr: 0.000001  loss: 2.2720 (2.2868)  time: 0.1287  data: 0.0018  max mem: 970
Epoch: [0]  [520/780]  eta: 0:00:43  lr: 0.000001  loss: 2.2767 (2.2867)  time: 0.1288  data: 0.0007  max mem: 970
Epoch: [0]  [530/780]  eta: 0:00:41  lr: 0.000001  loss: 2.2574 (2.2863)  time: 0.1244  data: 0.0012  max mem: 970
Epoch: [0]  [540/780]  eta: 0:00:39  lr: 0.000001  loss: 2.2672 (2.2861)  time: 0.1222  data: 0.0013  max mem: 970
Epoch: [0]  [550/780]  eta: 0:00:37  lr: 0.000001  loss: 2.2662 (2.2855)  time: 0.1224  data: 0.0004  max mem: 970
Epoch: [0]  [560/780]  eta: 0:00:35  lr: 0.000001  loss: 2.2564 (2.2854)  time: 0.1236  data: 0.0022  max mem: 970
Epoch: [0]  [570/780]  eta: 0:00:34  lr: 0.000001  loss: 2.2564 (2.2847)  time: 0.1290  data: 0.0021  max mem: 970
Epoch: [0]  [580/780]  eta: 0:00:32  lr: 0.000001  loss: 2.2550 (2.2845)  time: 0.1280  data: 0.0040  max mem: 970
Epoch: [0]  [590/780]  eta: 0:00:30  lr: 0.000001  loss: 2.2799 (2.2844)  time: 0.1218  data: 0.0046  max mem: 970
Epoch: [0]  [600/780]  eta: 0:00:28  lr: 0.000001  loss: 2.2665 (2.2840)  time: 0.1238  data: 0.0028  max mem: 970
Epoch: [0]  [610/780]  eta: 0:00:27  lr: 0.000001  loss: 2.2571 (2.2839)  time: 0.1226  data: 0.0027  max mem: 970
Epoch: [0]  [620/780]  eta: 0:00:25  lr: 0.000001  loss: 2.2604 (2.2837)  time: 0.1221  data: 0.0007  max mem: 970
Epoch: [0]  [630/780]  eta: 0:00:23  lr: 0.000001  loss: 2.2766 (2.2839)  time: 0.1270  data: 0.0001  max mem: 970
Epoch: [0]  [640/780]  eta: 0:00:22  lr: 0.000001  loss: 2.2933 (2.2841)  time: 0.1197  data: 0.0001  max mem: 970
Epoch: [0]  [650/780]  eta: 0:00:20  lr: 0.000001  loss: 2.2616 (2.2835)  time: 0.1154  data: 0.0007  max mem: 970
Epoch: [0]  [660/780]  eta: 0:00:18  lr: 0.000001  loss: 2.2471 (2.2832)  time: 0.1180  data: 0.0008  max mem: 970
Epoch: [0]  [670/780]  eta: 0:00:17  lr: 0.000001  loss: 2.2514 (2.2831)  time: 0.1209  data: 0.0003  max mem: 970
Epoch: [0]  [680/780]  eta: 0:00:15  lr: 0.000001  loss: 2.2712 (2.2831)  time: 0.1216  data: 0.0012  max mem: 970
Epoch: [0]  [690/780]  eta: 0:00:13  lr: 0.000001  loss: 2.2881 (2.2832)  time: 0.1208  data: 0.0022  max mem: 970
Epoch: [0]  [700/780]  eta: 0:00:12  lr: 0.000001  loss: 2.3005 (2.2836)  time: 0.1225  data: 0.0012  max mem: 970
Epoch: [0]  [710/780]  eta: 0:00:10  lr: 0.000001  loss: 2.2856 (2.2834)  time: 0.1197  data: 0.0001  max mem: 970
Epoch: [0]  [720/780]  eta: 0:00:09  lr: 0.000001  loss: 2.2506 (2.2826)  time: 0.1219  data: 0.0005  max mem: 970
Epoch: [0]  [730/780]  eta: 0:00:07  lr: 0.000001  loss: 2.2331 (2.2823)  time: 0.1235  data: 0.0025  max mem: 970
Epoch: [0]  [740/780]  eta: 0:00:06  lr: 0.000001  loss: 2.2675 (2.2820)  time: 0.1249  data: 0.0021  max mem: 970
Epoch: [0]  [750/780]  eta: 0:00:04  lr: 0.000001  loss: 2.2533 (2.2819)  time: 0.1237  data: 0.0006  max mem: 970
Epoch: [0]  [760/780]  eta: 0:00:03  lr: 0.000001  loss: 2.2678 (2.2816)  time: 0.1174  data: 0.0006  max mem: 970
Epoch: [0]  [770/780]  eta: 0:00:01  lr: 0.000001  loss: 2.2640 (2.2811)  time: 0.0833  data: 0.0001  max mem: 970
Epoch: [0]  [779/780]  eta: 0:00:00  lr: 0.000001  loss: 2.2415 (2.2810)  time: 0.0507  data: 0.0001  max mem: 970
Epoch: [0] Total time: 0:01:57 (0.1504 s / it)
Averaged stats: lr: 0.000001  loss: 2.2415 (2.2810)
Traceback (most recent call last):
  File "main.py", line 383, in <module>
    main(args)
  File "main.py", line 336, in main
    }, checkpoint_path)
  File "/users/mgovind/convit/utils.py", line 219, in save_on_master
    torch.save(*args, **kwargs)
  File "/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/serialization.py", line 374, in save
    _legacy_save(obj, opened_file, pickle_module, pickle_protocol)
  File "/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/serialization.py", line 214, in __exit__
    self.file_like.close()
OSError: [Errno 28] No space left on device
Traceback (most recent call last):
  File "/users/mgovind/.conda/envs/convitenv/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/users/mgovind/.conda/envs/convitenv/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/users/mgovind/.conda/envs/convitenv/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/users/mgovind/.conda/envs/convitenv/bin/python', '-u', 'main.py', '--model', 'convit_tiny', '--batch-size', '16', '--output_dir', 'exp/cvt-tiny/c10', '--data-path', './data', '--data-set', 'CIFAR10']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 1996413
Killing subprocess 1996414
Killing subprocess 1996415
Killing subprocess 1996416
